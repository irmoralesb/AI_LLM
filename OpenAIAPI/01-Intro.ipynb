{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bfef42",
   "metadata": {},
   "source": [
    "# Open AI API\n",
    "\n",
    "> API stands for Application Programming Interface\n",
    "\n",
    "It helps with:\n",
    "\n",
    "* Integrate AI into products\n",
    "* Work with models programmatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f637c",
   "metadata": {},
   "source": [
    "## Code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb2bfda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-ChTnHcBjwNzoYN45eCdbK93hJNeat', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It seems like your message may have been incomplete. How can I assist you today? If you have a specific prompt or question, feel free to share!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1764478667, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=31, prompt_tokens=12, total_tokens=43, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Here we load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "max_completion_tokens = 100\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_completion_tokens=max_completion_tokens,\n",
    "    messages=[{\"role\":\"user\",\"content\":\"INSERT YOUR PROMPT HERE\"}]\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649cae3",
   "metadata": {},
   "source": [
    "This is the response\n",
    "```\n",
    "ChatCompletion(\n",
    "    id='chatcmpl-ChT7CVReyCli2hY4RGfpG521WUzaM', \n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason='stop', \n",
    "            index=0, \n",
    "            logprobs=None, \n",
    "            message=ChatCompletionMessage(\n",
    "                content=\"It seems like you may have wanted to provide a specific prompt or question. Please go ahead and share what you'd like assistance with, and I'll be happy to help!\", \n",
    "                refusal=None, \n",
    "                role='assistant', \n",
    "                annotations=[], \n",
    "                audio=None, \n",
    "                function_call=None,\n",
    "                tool_calls=None)\n",
    "            )\n",
    "        ],\n",
    "    created=1764476058, \n",
    "    model='gpt-4o-mini-2024-07-18', \n",
    "    object='chat.completion',\n",
    "    service_tier='default',\n",
    "    system_fingerprint='fp_51db84afab',\n",
    "    usage=CompletionUsage(completion_tokens=33, prompt_tokens=12, total_tokens=45, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a1074",
   "metadata": {},
   "source": [
    "## Accessing the response text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b1c382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems like you may have wanted to provide a specific prompt or question. Please go ahead and share what you'd like assistance with, and I'll be happy to help!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a783e",
   "metadata": {},
   "source": [
    "## Cost\n",
    "\n",
    "* Usage costs dependent on the model and the number of tokens\n",
    "   * Model are priced by cost/tokens\n",
    "   * Input and output tokens may have different costs\n",
    "* Increasing `max_completion_tokens` increases cost\n",
    "\n",
    "### Calculating the Cost\n",
    "\n",
    "[https://openai.com/pricing](https://openai.com/pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "854d4936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost: 6.18e-05\n"
     ]
    }
   ],
   "source": [
    "# Define price per token\n",
    "input_token_price = 0.15 / 1_000_000\n",
    "output_token_price = 0.6 / 1_000_000\n",
    "\n",
    "# Extract token usage\n",
    "input_tokens = response.usage.prompt_tokens\n",
    "output_tokens =  max_completion_tokens\n",
    "\n",
    "cost = (input_tokens * input_token_price + output_tokens * output_token_price)\n",
    "print(f\"Estimated cost: {cost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
